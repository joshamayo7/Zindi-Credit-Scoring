{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Below are the feature descriptions.","metadata":{}},{"cell_type":"markdown","source":"## Description of variables in Train/Test.csv\n\n0. **ID**: A unique identifier for each entry in the dataset.\n\n1. **customer_id**: Unique identifier for each customer in the dataset.\n\n2. **country_id**: Identifier or code representing the country where the customer resides or where the loan was issued.\n\n3. **tbl_loan_id**: Unique identifier for each loan associated with the customer.\n\n4. **Total_Amount**: The total loan amount initially disbursed to the customer.\n\n5. **Total_Amount_to_Repay**: The total amount the customer is expected to repay, including principal, interest, and fees.\n\n6. **loan_type**: The category or type of loan.\n\n7. **disbursement_date**: The date when the loan amount was disbursed to the customer.\n\n8. **duration**: The length of the loan term, typically expressed in days\n\n9. **lender_id**: Unique identifier for the lender or institution that issued the loan.\n\n10. **New_versus_Repeat**: Indicates whether the loan is the customer's first loan (\"New\") or if the customer has taken loans before (\"Repeat\").\n\n11. **Amount_Funded_By_Lender**: The portion of the loan funded directly by the lender.\n\n12. **Lender_portion_Funded**: Percentage of the total loan amount funded by the lender.\n\n13. **due_date**: The date by which the loan repayment is due.\n\n14. **Lender_portion_to_be_repaid**: The portion of the outstanding loan that needs to be repaid to the lender.\n\n15. **target**: This variables takes the value 0 or 1. 1 means the customer defaulted on the loan, whereas 0 means, the customer paid the loan.\n","metadata":{}},{"cell_type":"code","source":"import warnings\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nfrom datetime import datetime\nfrom scipy.stats import zscore\nimport xgboost as xgb\nfrom sklearn.metrics import roc_curve,auc,confusion_matrix,accuracy_score,precision_score,classification_report,f1_score,make_scorer,precision_recall_curve\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold,RandomizedSearchCV, GridSearchCV, train_test_split,cross_val_score\nfrom bayes_opt import BayesianOptimization\nimport optuna\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import VotingClassifier, StackingClassifier\nimport seaborn as sns\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T23:11:39.916214Z","iopub.execute_input":"2025-01-15T23:11:39.916504Z","iopub.status.idle":"2025-01-15T23:11:46.735437Z","shell.execute_reply.started":"2025-01-15T23:11:39.916476Z","shell.execute_reply":"2025-01-15T23:11:46.734522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Just to ignore the warnings\nwarnings.filterwarnings('ignore')\n\n# Max columns\npd.set_option('display.max_columns', None)  # Ensure all columns are shown\npd.set_option('display.expand_frame_repr', False)","metadata":{"id":"2wtMxHSIRV6z","jupyter":{"is_executing":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing the data","metadata":{"id":"AL2irb45R86b"}},{"cell_type":"code","source":"# train and test set\ntrain = pd.read_csv(\"C:\\\\Users\\\\josha\\Downloads\\\\african-credit-scoring-challenge20241203-14702-1yayxml\\\\Train.csv\")\ntest = pd.read_csv(\"C:\\\\Users\\\\josha\\Downloads\\\\african-credit-scoring-challenge20241203-14702-1yayxml\\\\Test.csv\")","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.445972200Z","start_time":"2024-12-19T01:42:16.960086Z"},"id":"YKPb73YtSA-a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.446977Z","start_time":"2024-12-19T01:42:38.757901Z"},"id":"nkSunsobSS4z","outputId":"42a1f322-e14a-4d3a-8cd9-4c9b972930b4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display in the full format\npd.set_option('display.float_format', '{:.2f}'.format)\ntrain.describe()","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.464058700Z","start_time":"2024-12-19T01:43:00.784822Z"},"id":"tcETwL57VOy7","outputId":"81bd15b9-3cfc-4e90-d221-a666847ffbe6"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display in the full format\npd.set_option('display.float_format', '{:.2f}'.format)\ntest.describe()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Exploration and EDA","metadata":{"id":"tN8-m0gMWLJC"}},{"cell_type":"code","source":"# log transforming our numericals \nnumerical = ['Total_Amount','Total_Amount_to_Repay','duration','Amount_Funded_By_Lender','Lender_portion_Funded','Lender_portion_to_be_repaid']\nfor n in numerical:\n    train[f'{n}_log'] = np.log1p(train[n])\n    test[f'{n}_log'] = np.log1p(test[n])","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.468583Z","start_time":"2024-12-19T01:43:00.967785Z"},"id":"Nvh-tzGiZ5ut"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Changing ID columns into objects\ntest['lender_id'] = test['lender_id'].astype('object')\ntest['customer_id'] = test['customer_id'].astype('object')\ntest['tbl_loan_id'] = test['tbl_loan_id'].astype('object')","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.492315500Z","start_time":"2024-12-19T01:43:01.056272Z"},"id":"s4XdLLAtLhYU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Processing dates and splitting into month, day, year\ndef date_processing(df):\n    df['disbursement_date'] = pd.to_datetime(df['disbursement_date'])\n    df['due_date'] = pd.to_datetime(df['due_date'])\n    \n    # Get month, day and year\n    df['disbursement_year'] = df['disbursement_date'].dt.year\n    df['disbursement_month'] = df['disbursement_date'].dt.month\n    df['disbursement_day'] = df['disbursement_date'].dt.day\n    \n    df['due_year'] = df['due_date'].dt.year\n    df['due_month'] = df['due_date'].dt.month\n    df['due_day'] = df['due_date'].dt.day\n    return df\n\ntrain = date_processing(train)\ntest = date_processing(test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of loans taken by each customer\ndef loans_taken(df):\n    loan_counts = df.groupby('customer_id').agg(loans_taken=('customer_id','count'))\n    df = df.merge(loan_counts, on='customer_id')\n    return df\n\ntrain = loans_taken(train)\ntest = loans_taken(test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# How does my new feature look between the target classes?\nsns.boxplot(x='target',y='loans_taken',data=train)\nplt.xlabel('The loan default class')\nplt.ylabel('Number of loans taken')\nplt.title('Number of loans taken per default class')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Investigate the categoricals\ntrain['due_month_categorical'] = train['due_month'].astype('object')\ntrain['disbursed_month_categorical'] = train['disbursement_month'].astype('object')\ntrain['target'] = train['target'].astype('object')\ntrain['lender_id'] = train['lender_id'].astype('object')\ntrain['customer_id'] = train['customer_id'].astype('object')\ntrain['tbl_loan_id'] = train['tbl_loan_id'].astype('object')\n\n# Just checking the value counts for my categoricals\nexclusions = ['ID', 'disbursement_date','due_date','customer_id','tbl_loan_id'] # Too many to visually see\ncategoricals = train.select_dtypes(include='object')\nfor c in categoricals.columns:\n  if c not in exclusions:\n    print(f'{c}: {categoricals[c].value_counts()}')","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.494312500Z","start_time":"2024-12-19T01:43:01.126029Z"},"id":"dx8__eA9WNKV","outputId":"db50a62a-36c1-4609-910b-6078d32f65c7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Imbalanced target variable, this would need addressing.","metadata":{"id":"nRrv7jIBXqbb"}},{"cell_type":"code","source":"# Subsetting for just the log transformed features\nnumericals = train[['Total_Amount','Total_Amount_to_Repay','duration','Amount_Funded_By_Lender','Lender_portion_Funded','Lender_portion_to_be_repaid','Total_Amount_log','Total_Amount_to_Repay_log','duration_log','Amount_Funded_By_Lender_log','Lender_portion_Funded_log','Lender_portion_to_be_repaid_log']]\nfor n in numericals.columns:\n  bin = int(np.sqrt(len(train)))  # Setting the number of bins as the square root of the length\n\n  plt.figure(figsize=(10,5))\n  plt.hist(train[n], bins=bin)\n  plt.title(f'Distribution of {n}')\n  plt.xlabel(n)\n  plt.ylabel('Frequency')\n  plt.show()","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.494312500Z","start_time":"2024-12-19T01:43:01.260527Z"},"id":"f2eFCuraXxtd","outputId":"5edd4be4-d648-40dc-aa99-42309dac9c59"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Log transformed my values due to skewing. Very difficult to see the trends of the raw values.","metadata":{"id":"SyFiZJqtH9F6"}},{"cell_type":"code","source":"# Boxplots of target vs features, using numericals and exclusions from before\nfor n in numericals.columns:\n  plt.figure(figsize=(10,5))\n  sns.boxplot(x='target', y=n, data=train)\n  plt.title(f'Box plot of {n} against target')\n  plt.xlabel('Loan default')\n  plt.ylabel(n)\n  plt.show()\n","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.495817900Z","start_time":"2024-12-19T01:43:03.771024Z"},"id":"zqQa_K7EH3Tx","outputId":"7843e463-2fd5-47a0-dda3-f06e9cd9d7e8","scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Again, due to the data spread, it's easier to spot trends in the log transformed data.","metadata":{"id":"D00avWOPI4ke"}},{"cell_type":"code","source":"# Countplots for all my categorical features\nexclude = ['ID','customer_id','tbl_loan_id','country_id']\nfor c in categoricals.columns:\n  if c not in exclude:\n    plt.figure(figsize=(10,5))\n    sns.countplot(x=c, data=train)\n    plt.title(f'Count plot of {c}')\n    plt.xlabel(c)\n    plt.ylabel('Frequency')\n    plt.xticks(rotation=45)\n    plt.show()","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.497829800Z","start_time":"2024-12-19T01:43:05.166341Z"},"id":"sg1_xMLHI765","outputId":"9d9559e1-ffa5-4858-f943-19c0ab4f2276","scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1. A very dominant lender id and loan_type in the dataset\n2. Majority are repeat loans\n3. Massive class imbalance in our target class, very few loan defaults in our dataset\n4. Most of our loans are taken and paid in the second half of the year","metadata":{}},{"cell_type":"code","source":"# Splitting our categorical features by our target variable\nfor c in categoricals.columns:\n  if c not in exclude:\n    plt.figure(figsize=(10,5))\n    sns.countplot(x=c, data=train, hue='target')\n    plt.title(f'Count plot of {c}')\n    plt.xlabel(c)\n    plt.ylabel('Frequency')\n    plt.xticks(rotation=45)\n    plt.show()","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.518358900Z","start_time":"2024-12-19T01:43:06.669238Z"},"id":"Im7SuS5yKmGT","outputId":"53353a72-9965-45da-8154-189524d6b4e5","scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"The below feature had the biggest impact.","metadata":{}},{"cell_type":"code","source":"# Creating a ratio of how much is left of the debt\ntrain['repayment_ratio'] = train['Total_Amount_to_Repay'] / train['Total_Amount']\ntest['repayment_ratio'] = test['Total_Amount_to_Repay'] / test['Total_Amount']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Binning our duration column to reduce some noise\nbins = [0,30,180,365, float('inf')]\nlabels = ['Short-term','Medium-term','Long-term','Very-long term']\n\ntrain['Duration category'] = pd.cut(train['duration'], bins=bins, labels=labels)\ntest['Duration category'] = pd.cut(test['duration'], bins=bins, labels=labels)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation matrix\n# nums = exclusive_df.select_dtypes(exclude='object')\nplt.figure(figsize=(12,6))\ncorr_matrix = numericals.corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.522365900Z","start_time":"2024-12-19T01:45:21.070166Z"},"id":"Y4pQOPvzSaGC","outputId":"03fd127a-be2e-4547-e5eb-6cc75ccd0ccc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Our features are highly correlated as a number of columns are showing the same thing, thus will either use log transformed or raw data and not both.","metadata":{"id":"OO7a9ZvoSvDE"}},{"cell_type":"code","source":"# Do we have multiple tbl_loan_ids?\nthreshold = 1\nfocus = train['tbl_loan_id'].value_counts()\nneed = focus[focus > threshold]\n\n# Duplicates\nduplicated = train[train['tbl_loan_id'].isin(need.index)]\nduplicated","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Customer ID?\n# Do we have the same customer ID appearing multiple times\nthreshold = 1\nfocus = train['customer_id'].value_counts()\nneed = focus[focus > threshold]\n\n# How is the target class split for duplicate customer_ids\nduplicated_id = train[train['customer_id'].isin(need.index)]\nduplicated_id = duplicated_id.sort_values(by='customer_id', ascending=False)\nduplicated_id['target'].value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This function shows how many lenders are in a loan\ndef unique_id(df): \n    check = pd.DataFrame(df['tbl_loan_id'].value_counts()).reset_index()\n    df = df.merge(check, on='tbl_loan_id',how='left')\n    df = df.rename(columns={'count':'Lender_numbers'})\n    return df\n\ntrain = unique_id(train)\ntest = unique_id(test)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training lenders:{train['Lender_numbers'].value_counts()}\")\nprint(f\"Test set lenders:{test['Lender_numbers'].value_counts()}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# What's the spread of years for disbursement and due dates\ndef date_processing(df):\n    df['disbursement_date'] = pd.to_datetime(df['disbursement_date'])\n    df['due_date'] = pd.to_datetime(df['due_date'])\n    \n    # Get month, day and year\n    df['disbursement_year'] = df['disbursement_date'].dt.year\n    df['disbursement_month'] = df['disbursement_date'].dt.month\n    df['disbursement_day'] = df['disbursement_date'].dt.day\n    \n    df['due_year'] = df['due_date'].dt.year\n    df['due_month'] = df['due_date'].dt.month\n    df['due_day'] = df['due_date'].dt.day\n    return df\n\ntrain = date_processing(train)\ntest = date_processing(test)\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Changing the lender_id dtypes\ntrain['lender_id'] = train['lender_id'].astype(object)\ntest['lender_id'] = test['lender_id'].astype(object)","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.531897600Z","start_time":"2024-12-19T01:45:22.336589Z"},"id":"ZlNC3YB7T9jA"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below is the economics indicators data, providing further info on the countries. Including them improved my score locally but not on the leaderboard. I therefore didn't include them in my features but have just shown them below.","metadata":{}},{"cell_type":"code","source":"# Economic indicators\nindicators_df = pd.read_csv('C:\\\\Users\\\\josha\\\\Downloads\\\\african-credit-scoring-challenge20241203-14702-1yayxml\\economic_indicators.csv')\nindicators_df.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Melt the DataFrame to make years rows instead of columns\nmelted = pd.melt(indicators_df, id_vars=[\"Country\", \"Indicator\"], var_name=\"Year\", value_name=\"Value\")\n\n# Pivot to make each indicator its own column\neconomics_df = melted.pivot_table(index=[\"Country\", \"Year\"], columns=\"Indicator\", values=\"Value\").reset_index()\n\n# Keep the year numericals\neconomics_df['Year'] = economics_df['Year'].str[2:].astype(int)\neconomics_df.head()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A fair amomunt of null values, in addition there's no 2024 data\neconomics_df.isnull().sum()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I commented out the merging as I didn't include the features but the code shows my approach. ","metadata":{}},{"cell_type":"code","source":"# # Some merging\n# train = train.merge(economics_df, left_on=['country_id','disbursement_year'], right_on=['Country','Year'],how='left')\n# test = test.merge(economics_df, left_on=['country_id','disbursement_year'], right_on=['Country','Year'],how='left')\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Drop these cols\n# train = train.drop(columns=['Average precipitation in depth (mm per year)','Fossil fuel energy consumption (% of total)'])\n# test = test.drop(columns=['Average precipitation in depth (mm per year)','Fossil fuel energy consumption (% of total)'])\n# # test = test.fillna(0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Created this function to get the actual day of the week from train and test set\ndef get_day_name(df):\n    # Disbursement Date and due date\n    df['disbursement_date'] = pd.to_datetime(df['disbursement_date'], format=\"%Y-%m-%d\")\n    df['due_date'] = pd.to_datetime(df['due_date'], format=\"%Y-%m-%d\")\n    \n    # Extract day names\n    df['Disbursement Day'] = df['disbursement_date'].dt.strftime(\"%A\")\n    df['Due Day'] = df['due_date'].dt.strftime(\"%A\")\n    return df","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.532712600Z","start_time":"2024-12-19T01:45:22.479890Z"},"id":"IaAMQEsgxgoI","outputId":"16575ba8-2f74-438d-d138-96e677fd2e75"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = get_day_name(train)\ntest = get_day_name(test)","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.533718500Z","start_time":"2024-12-19T01:45:22.562560Z"},"id":"x0kiS6_2xNix","outputId":"f45172d3-95d8-48e5-f8c0-9ea8d1e79362"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Similar spread across\nprint(test['Disbursement Day'].value_counts())\nprint(test['Due Day'].value_counts())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Corr matrix\nnums = train.select_dtypes(exclude=['object','category'])\n\n\nplt.figure(figsize=(18,10))\ncorr_matrix = nums.corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Quite a bit of multicolinearity","metadata":{}},{"cell_type":"code","source":"# This feature simply shows the ratio of new to returning customers each lender has.\ndef new_vs_returning(df):\n    # Lenders and returning customers?\n    grouped_ratio = df.groupby(['lender_id','New_versus_Repeat']).agg(counts=('New_versus_Repeat','count'))\n    \n    # Creating a new to repeat ratio\n    loan_counts = grouped_ratio.unstack(fill_value=0)['counts']\n    loan_counts['new vs repeat ratio'] = loan_counts['New Loan'] / loan_counts['Repeat Loan']\n    \n    # Reset the index of loan_counts\n    loan_counts = loan_counts.reset_index()\n    df = df.merge(loan_counts[['lender_id','new vs repeat ratio']], on='lender_id')\n    return df\n\ntrain = new_vs_returning(train)\ntest = new_vs_returning(test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Experimenting with some interaction features\ndef final_features(df):\n    df['lender_funded_ratio'] = df['Lender_portion_Funded'] / df['Total_Amount']\n    df['lender_repay_ratio'] = df['Lender_portion_to_be_repaid'] / df['Total_Amount_to_Repay']\n    return df\n\n# Applying it\ntrain = final_features(train)\ntest = final_features(test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replaced infinite values with 0 for cases where denominator was 0\ntrain['lender_repay_ratio'] = train['lender_repay_ratio'].replace(np.inf,0)\ntest['lender_repay_ratio'] = test['lender_repay_ratio'].replace(np.inf,0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setting weekdays or weekends\ndef weekday_or_weekend(df):\n    weekdays = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n\n    # Set as weekday or weekend for some more filtering\n    df['weekday/weekend'] = np.where(df['Due Day'].isin(weekdays),'Weekday','Weekend')\n    return df\n\ntrain = weekday_or_weekend(train)\ntest = weekday_or_weekend(test)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Outlier investigation","metadata":{}},{"cell_type":"code","source":"# Computing z scores for numericals\n\nnums = train[['Total_Amount','Total_Amount_to_Repay','Amount_Funded_By_Lender','Lender_portion_Funded','Lender_portion_to_be_repaid']]\nfor col in nums.columns:\n    nums[f'{col}_zscore'] = zscore(nums[col])\n\nnums","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filtering the zscore columns\nzscore_cols = [col for col in nums.columns if '_zscore' in col]\n\n# Any value wth a zscore of >3 is considered an outlier in this case\noutlier_rows = nums[(nums[zscore_cols]>3).any(axis=1)]\noutlier_rows","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mapping it back to the original dataframe\noutliers_df = train.loc[outlier_rows.index]\noutliers_df.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outliers_df.groupby(['lender_id','New_versus_Repeat','target']).agg(ratio = ('New_versus_Repeat','count'))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lender ID 245684 had most of their loan defaults coming from new loans, which is different from all the rest.","metadata":{}},{"cell_type":"code","source":"# Among our outliers who defaulted, is there any trend?\ndefaults = outliers_df[outliers_df['target']==1]\ndefaults['lender_id'].value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Features","metadata":{"id":"sD_2HS9pHmbg"}},{"cell_type":"markdown","source":"In future, a more robust feature selection method will be needed, as my approach was quite experimental and reactive based on feature importance and the impact features had on the leaderboard score and my local score.","metadata":{}},{"cell_type":"code","source":"common_features = [\n    'lender_id',\n    'loan_type',\n    'New_versus_Repeat',\n    'Amount_Funded_By_Lender',\n    'Lender_portion_Funded',\n    'Lender_portion_to_be_repaid',\n    'disbursement_month',\n    'disbursement_day',\n    'due_year',\n    'due_month',\n    'due_day',\n    'Disbursement Day',\n    'Due Day',\n    'Duration category',\n    'repayment_ratio',\n    'loans_taken',\n    'Lender_numbers',\n    'new vs repeat ratio',\n    'weekday/weekend',\n    'lender_funded_ratio',\n    'lender_repay_ratio'\n]\n\npredictors = train[common_features + ['target']]  # Add target only for train\npredictions = test[common_features]\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final confirmation\npredictions.isnull().sum()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final heatmap\nnums = predictors.select_dtypes(exclude=['object','category'])\ncorr = nums.corr()\nplt.figure(figsize=(12,6))\nsns.heatmap(corr, annot=True)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NOTE.Despite the multicolinearity, this combination gave the best score on the public leaderboard so I chose to keep it this way. In hindsight, I should have removed these highly correlated features.","metadata":{}},{"cell_type":"markdown","source":"# Baseline model","metadata":{"id":"Y-gAxxjyI7U1"}},{"cell_type":"markdown","source":"Starting with a baseline model to see how our model will learn. Will go straight to XGBoost.\nIn the next challenge, i'll make use of StratifiedGroupKFold, grouping by customer_id to ensure that all customer_ids are in the same group meaning there'll be no leakage.","metadata":{"id":"CtP04gXzI9kn"}},{"cell_type":"code","source":"#One hot encoding training, val and test set\nprocessed_x = pd.get_dummies(predictors.drop(columns=['target']))\nprocessed_y = predictors['target']\n\n\nprocessed_test = pd.get_dummies(predictions)\n\n# Aligning the dfs to ensure we have the same columns\nfinal_train, X_test = processed_x.align(processed_test, join='outer', axis=1, fill_value=0)\n\n# Initialize Stratified K-Fold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Looping through each fold\nfold_results = []\nscaler = StandardScaler()\n\nfor fold, (train_index, val_index) in enumerate(skf.split(final_train, processed_y)):\n    print(f\"Processing Fold {fold+1}...\")\n\n    # Train/Validation split for the current fold\n    X_train, X_val = final_train.iloc[train_index], final_train.iloc[val_index]\n    y_train, y_val = processed_y.iloc[train_index], processed_y.iloc[val_index]\n    \n# Ensuring y_train and y_val are integers\ny_train = y_train.astype('int64')\ny_val = y_val.astype('int64')\n\n#Scale the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.555804900Z","start_time":"2024-12-19T01:46:20.272915Z"},"id":"hxJnfi40JIwl"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In order to address the class imbalance, I set the class_weights manually which will be passed during the fit. This brought me significantly better results than upsampling using SMOTE.","metadata":{}},{"cell_type":"code","source":"# Assuming binary classification\nclass_weights = {0: 1, 1: 3}  # Higher weight for minority class\n\n# Use sample_weight during fitting\nsample_weight = y_train.map(class_weights)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Started the tuning with a small grid and then moved to other methods. Medium max depth and min child weight were used to ensure we have no extremes of underfitting/overfitting.","metadata":{}},{"cell_type":"code","source":"# Hyperparameter tuning\nparam_grid_x = {\n    'learning_rate': [0.01,0.1],\n    'max_depth':[5,6],\n    'n_estimators': [200, 300],\n    'min_child_weight': [5,6]\n}\n\n\nxgbmodel = xgb.XGBClassifier()\nxgb_c = RandomizedSearchCV(xgbmodel,param_grid_x,cv=5,scoring='f1')\nxgb_c.fit(X_train_scaled,y_train,sample_weight=sample_weight) # Tuning with the weights\n\nprint(\"Tuned XGB Parameters: {}\".format(xgb_c.best_params_))\nprint(\"Best score is {}\".format(xgb_c.best_score_))\n\nxg_params = xgb_c.best_params_","metadata":{"ExecuteTime":{"end_time":"2024-12-19T15:38:29.559817200Z","start_time":"2024-12-19T01:46:46.476026Z"},"id":"roc6cVRfXBjD","outputId":"807ce1a2-89a4-43da-f318-d4f3aa4ed929"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After the initial tuning, I made use of Bayesian Optimization and Optuna as well. The Optuna gave me better results on the lb but as expected, both gave better F1 than the simple grid.","metadata":{}},{"cell_type":"code","source":"# Bayesian Optimization process\ndef xgb_f1_eval(learning_rate, max_depth, n_estimators, min_child_weight):\n    # Convert inputs to integers where required\n    max_depth = int(max_depth)\n    n_estimators = int(n_estimators)\n    min_child_weight = int(min_child_weight)\n    \n    # Initialize XGBClassifier with weights for the minority class\n    model = xgb.XGBClassifier(\n        learning_rate=learning_rate,\n        max_depth=max_depth,\n        n_estimators=n_estimators,\n        min_child_weight=min_child_weight,\n        random_state=42,\n        use_label_encoder=False,\n        eval_metric='logloss',\n        scale_pos_weight=3  # Adjusting for class imbalance\n    )\n    \n    # Train the model\n    model.fit(X_train_scaled, y_train)\n    \n    # Predict and evaluate F1 score\n    y_pred = model.predict(X_val_scaled)\n    f1 = f1_score(y_val, y_pred)\n    return f1\n\n# Defining the parameter search space\nparam_bounds = {\n    'learning_rate': (0.01, 0.2),\n    'max_depth': (5, 10),\n    'n_estimators': (100, 500),\n    'min_child_weight': (4, 10)\n}\n\n# Run Bayesian Optimization\noptimizer = BayesianOptimization(f=xgb_f1_eval, pbounds=param_bounds, random_state=42)\noptimizer.maximize(init_points=5, n_iter=25)\n\n# Best parameters and F1 score\nbest_params = optimizer.max['params']\nbest_params['max_depth'] = int(best_params['max_depth'])\nbest_params['n_estimators'] = int(best_params['n_estimators'])\nbest_params['min_child_weight'] = int(best_params['min_child_weight'])\nbest_f1_score = optimizer.max['target']\n\nbest_params, best_f1_score","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Objective function for Optuna\ndef objective(trial):\n    # Defining the parameter search space\n    params = {\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n        'max_depth': trial.suggest_int('max_depth', 5, 8),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n        'min_child_weight': trial.suggest_int('min_child_weight', 5, 10),\n        'scale_pos_weight': 3,  # Adjust for class imbalance,\n        'random_state':42,\n        'use_label_encoder': False,\n        'eval_metric': 'logloss'\n    }\n\n    # Initialize the XGBoostClassifier\n    model = xgb.XGBClassifier(**params)\n    \n    # Train the model\n    model.fit(X_train_scaled, y_train)\n    \n    # Predict on validation set\n    y_pred = model.predict(X_val_scaled)\n    \n    # Evaluate F1 score\n    f1 = f1_score(y_val, y_pred)\n    return f1\n\n# Create an Optuna study\nstudy = optuna.create_study(direction=\"maximize\")  # Maximize the F1 score\nstudy.optimize(objective, n_trials=30)\n\n# Get the best parameters and score\nbest_paramss = study.best_params\nbest_f1_score = study.best_value\n\nprint(\"Best Parameters:\", best_paramss)\nprint(\"Best F1 Score:\", best_f1_score)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#XGBoost model\nxgb_model = xgb.XGBClassifier(random_state=42, **best_params) # Trying Bayesian params\n\nxgb_model.fit(X_train_scaled,y_train,sample_weight=sample_weight)\ny_pred = xgb_model.predict(X_test_scaled)\n\n#Matrix of the train data\ntraining_set = xgb_model.predict(X_train_scaled)\nprint('Trained data matrix:',confusion_matrix(y_train,training_set))\nprint('Training set:',accuracy_score(y_train,training_set))\nprint(classification_report(y_train,training_set))\n\n#Matrix of val data\nval_set = xgb_model.predict(X_val_scaled)\nprint('Validation data matrix:',confusion_matrix(y_val,val_set))\nprint('Validation set:',accuracy_score(y_val,val_set))\nprint(classification_report(y_val,val_set))","metadata":{"id":"SLtvcjVMXFYj","outputId":"40b329cc-9407-4766-fde3-a50a8d8de326","scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These results show a good balance between classes which is good to see considering the class imbalance. Just need to ensure that there was no data leakage anywhere.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Below shows that the CV score for F1 was 0.86. Given our standard deviation is less than 0.2 of our mean, we can conclude that the model's performance is stable.","metadata":{}},{"cell_type":"code","source":"# Define the k-fold cross-validation\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Using F1 score\nf1_scorer = make_scorer(f1_score)\n\n# Perform cross-validation\ncv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, cv=kfold, scoring=f1_scorer)\n\n# Output the scores\nprint(f\"Cross-Validation F1 Scores: {cv_scores}\")\nprint(f\"Mean F1 Score: {cv_scores.mean():.4f}\")\nprint(f\"Standard Deviation of F1 Scores: {cv_scores.std():.4f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Adjusting the decision boundary but didn't get any difference.","metadata":{}},{"cell_type":"code","source":"# Adjusted threshold\n# Predict probabilities\ny_pred_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n\n# Adjust threshold\nthreshold = 0.45\ny_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict probabilities\ny_pred_proba_val = xgb_model.predict_proba(X_val_scaled)[:, 1]\n\n# Adjust threshold\nthreshold = 0.45\ny_pred_adjusted_val = (y_pred_proba_val >= threshold).astype(int)\n\n# # Evaluate performance\nprint('Validation data matrix:',confusion_matrix(y_val,y_pred_adjusted_val))\nprint('Validation set:',accuracy_score(y_val,y_pred_adjusted_val))\nprint(classification_report(y_val, y_pred_adjusted_val))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"# Feature importance\nfeature_importances = pd.Series(xgb_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\nprint(feature_importances)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the feature importances\nplt.figure(figsize=(12, 8))  \nsns.barplot(x=feature_importances.values[:20], y=feature_importances.index[:20], palette=\"viridis\")  # Top 20 features\nplt.title(\"Feature Importances from XGBoost\")\nplt.xlabel(\"Importance Score\")\nplt.ylabel(\"Features\")\nplt.tight_layout()  \nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tuning and Ensemble","metadata":{}},{"cell_type":"markdown","source":"To boost the results, I incorporated an ensemble approach adding Catboost and LGBM classifiers, and then using Stacking/Voting to make the predictions. In this situation the Voting Classifier produced better lb results. Did a simpler param tune for both of these but in future might also run Optuna on them to maximise accuracy.","metadata":{}},{"cell_type":"code","source":"# Params for catboost\nparam_grid_r = {\n    'iterations': [100],               # Number of boosting iterations. Any higher and processing time is too long\n    'learning_rate': [0.03, 0.15],           \n    'depth': [6, 8],                        \n    'l2_leaf_reg': [3, 7],                  # L2 regularization strength\n    'bagging_temperature': [3, 5],          \n}\n\ncatboost = CatBoostClassifier()\ncat = RandomizedSearchCV(catboost,param_grid_r,n_iter=5,cv=5,scoring='f1')\ncat.fit(X_train_scaled,y_train,sample_weight=sample_weight)\n\nprint(\"Tuned RF Parameters: {}\".format(cat.best_params_))\nprint(\"Best score is {}\".format(cat.best_score_))\n\ncat_params = cat.best_params_","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lightgbm params\nparam_grid_l = {\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],  \n    'max_depth': [4, 5, 6, 7],  \n    'n_estimators': [100, 200, 300, 500],  \n    'min_child_weight': [3, 5, 10],  \n    'subsample': [0.6, 0.8, 1.0],  \n    'colsample_bytree': [0.6, 0.8, 1.0]  \n}\n\nlgbmodel = LGBMClassifier()\nlgb_c = RandomizedSearchCV(lgbmodel,param_grid_x,cv=5,scoring='f1')\nlgb_c.fit(X_train_scaled,y_train,sample_weight=sample_weight)\n\nprint(\"Tuned LGB Parameters: {}\".format(lgb_c.best_params_))\nprint(\"Best score is {}\".format(lgb_c.best_score_))\n\nlg_params = lgb_c.best_params_","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# My models\nxgb_modell = xgb.XGBClassifier(**best_params)  \ncat_model = CatBoostClassifier(**cat_params, random_state=42)\nlgb_model = LGBMClassifier(**lg_params)  # LightGBM model\n\n# Fit models individually\nxgb_modell.fit(X_train_scaled, y_train,sample_weight=sample_weight)\ncat_model.fit(X_train_scaled, y_train,sample_weight=sample_weight)\nlgb_model.fit(X_train_scaled, y_train, sample_weight=sample_weight)\n\n# Evaluate individual models\nfor model, name in zip([xgb_modell, cat_model, lgb_model], ['XGBoost', 'Catboost','Light GBM']):\n    y_val_pred = model.predict(X_val_scaled)\n    print(f\"{name} F1 Score: {f1_score(y_val, y_val_pred):.4f}\")\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VotingClassifier\nvoting_clf = VotingClassifier(\n    estimators=[('xgb', xgb_modell), ('cat', cat_model), ('lgb', lgb_model)],\n    voting='soft',\n    weights=[0.4, 0.3, 0.3]# Use 'soft' for probabilities, weighted XGBoost a bit higher\n)\nvoting_clf.fit(X_train_scaled, y_train)\n\n# Evaluate on validation set\ny_val_pred = voting_clf.predict(X_val_scaled)\nprint(f\"VotingClassifier F1 Score: {f1_score(y_val, y_val_pred):.4f}\")\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score\n\n# Define the k-fold cross-validation\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Using F1 score\nf1_scorer = make_scorer(f1_score)\n\n# Perform cross-validation\ncv_scores = cross_val_score(voting_clf, X_train_scaled, y_train, cv=kfold, scoring=f1_scorer)\n\n# Output the scores\nprint(f\"Cross-Validation F1 Scores: {cv_scores}\")\nprint(f\"Mean F1 Score: {cv_scores.mean():.4f}\")\nprint(f\"Standard Deviation of F1 Scores: {cv_scores.std():.4f}\")","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Stacking didn't give me good results in this occasion.","metadata":{}},{"cell_type":"code","source":"# # StackingClassifier\n# stacking_clf = StackingClassifier(\n#     estimators=[('xgb', xgb_modell), ('cat', cat_model), ('lgb', lgb_model)],\n#     final_estimator=xgb.XGBClassifier(random_state=42),\n#     cv=5\n# )\n# stacking_clf.fit(X_train_scaled, y_train)\n\n# # Evaluate on validation set\n# y_val_pred = stacking_clf.predict(X_val_scaled)\n# print(f\"StackingClassifier F1 Score: {f1_score(y_val, y_val_pred):.4f}\")\n","metadata":{"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n# Predict probabilities\ny_val_probs = voting_clf.predict_proba(X_val_scaled)[:, 1]\n\nprecision, recall, thresholds = precision_recall_curve(y_val, y_val_probs)\nf1_scores = 2 * (precision * recall) / (precision + recall)\noptimal_idx = f1_scores.argmax()\noptimal_threshold = thresholds[optimal_idx]\n\nprint(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n\n# Predict with adjusted threshold\ny_val_pred = (y_val_probs >= optimal_threshold).astype(int)\nprint(f\"Adjusted F1 Score: {f1_score(y_val, y_val_pred):.4f}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test_pred = voting_clf.predict(X_test_scaled)\n# Predict probabilities\ny_pred_probab = voting_clf.predict_proba(X_test_scaled)[:, 1]\n\n# Adjust threshold\nthreshold = optimal_threshold\ny_pred_adjusted = (y_pred_probab >= threshold).astype(int)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict probabilities\ny_pred_proba_valx = voting_clf.predict_proba(X_val_scaled)[:, 1]\n\n# Adjust threshold\nthreshold = optimal_threshold\ny_pred_adjusted_val = (y_pred_proba_valx >= threshold).astype(int)\n\n# # Evaluate performance\nprint('Validation data matrix:',confusion_matrix(y_val,y_pred_adjusted_val))\nprint('Validation set:',accuracy_score(y_val,y_pred_adjusted_val))\nprint(classification_report(y_val, y_pred_adjusted_val))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{"id":"2ErAAHlQcG8Q"}},{"cell_type":"code","source":"test['ID']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.Target = y_pred_adjusted\n\n# Create submission DataFrame\nsubmission = pd.DataFrame({\"ID\": test[\"ID\"],\n                           \"Target\": test.Target})\nsubmission","metadata":{"id":"qbvm12MecNp0","outputId":"4b193a63-02e5-4a3a-86eb-ca6b084f1fdd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create submission csv file csv file\nsubmission.to_csv('adjusted_submission.csv', index = False)\n","metadata":{"id":"ddbaU4gIcRic","outputId":"4e781396-ddd4-4aab-8fea-4b72ac219479"},"outputs":[],"execution_count":null}]}